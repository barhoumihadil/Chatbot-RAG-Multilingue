from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from scraping import scrape_navitrends_dynamic
from langchain_huggingface import HuggingFaceEmbeddings

def main():
    
    text = scrape_navitrends_dynamic()
    print(text[:500], flush=True)  
    print(len(text), flush=True)   

    
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    docs = splitter.split_text(text)
    print(f"ğŸ“¦ {len(docs)} chunks crÃ©Ã©s", flush=True)

    
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    
    vectorstore = FAISS.from_texts(docs, embeddings)
    print("ğŸ—ƒï¸ Index FAISS crÃ©Ã© avec succÃ¨s", flush=True)

    
    vectorstore.save_local("faiss_index")
    print("ğŸ’¾ Index sauvegardÃ© localement dans 'faiss_index'", flush=True)

if __name__ == "__main__":
    main()
